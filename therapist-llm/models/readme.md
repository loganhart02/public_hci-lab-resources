# Models to consider for training

there are really two types of models we can use and that is a normal LLM like llama or GPT or a MOE model like grok or mixtral. from reading the llama3 paper it seems that a normal llm will be fine and the most important thing is dataset quality starting with that might be best. for an MOE model we might start with grok or a mixtral model both of those are at the top right now. 


## Paper links
- **Llama3** : https://ai.meta.com/blog/meta-llama-3/
- **mixtral model**: https://arxiv.org/abs/2401.04088
- **grok**: https://x.ai/blog/grok
 